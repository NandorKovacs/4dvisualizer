\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % this is needed for umlauts
\usepackage[ngerman, english]{babel} % this is needed for umlauts
\usepackage[T1]{fontenc}    % this is needed for correct output of umlauts in pdf
\usepackage{csquotes}
\usepackage{amsmath,systeme}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{xcolor}
\usepackage{hyperref}

\definecolor{dark-green}{rgb}{0.0, 0.4, 0.0}
\newcommand{\code}[1]{{\color{dark-green}\texttt{\textbf{#1}}}}
\newtheorem{lemma}{Lemma}
\newcommand{\R}{\ensuremath{\mathbb{R}}}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

\title{4d visualisierungs Engine mit einer 3d Benutzeroberfläche als Hilfestellung beim Lernen und Experimentieren}
% \author{
%         Vitaly Surazhsky \\
%                 Department of Computer Science\\
%         Technion---Israel Institute of Technology\\
%         Technion City, Haifa 32000, \underline{Israel}
%             \and
%         Yossi Gil\\
%         Department of Computer Science\\
%         Technion---Israel Institute of Technology\\
%         Technion City, Haifa 32000, \underline{Israel}
% }
% \date{\today}

\begin{document}
\maketitle
\selectlanguage{english}
\begin{abstract}
	Ziel dieser Arbeit ist, vierdimensionale Würfel im vierdimensionalen Raum
	darzustellen.  Die Projektionsmethode, um den vierdimensionalen Raum in einem
	dreidimensionalen Raum darzustellen, kann man sich folgenderweise am
	einfachsten vorstellen: Man nimmt einen Kuchen und schneidet ihn in die
	Hälfte. Die Schnittfläche wird eine zweidimensionale Fläche. Anders gesagt,
	habe ich einen Körper im dreidimensionalen Raum, und schneide es mit einem
	zweidimensionalen Raum (also einer Ebene). Ähnlich nehme ich eine
	`Hyperebene', also einen dreidimensionalen Raum, und schneide damit den
	vierdimensionalen Raum. Der Schnittköper wird mit Hilfe des Koordinatensystems
	des Schnittraumes auf dem Bildschirm visualisiert.
\end{abstract}
\selectlanguage{ngerman}
\newpage
\tableofcontents
\pagebreak
% \section{Inhaltsverzeichnis}
% Überblick über den Aufbau: Gliederung in Kapitel und Unterkapitel. Vorwort
% (nicht obligatorisch): Das Vorwort enthält Dinge, die nicht in die Arbeit
% selbst gehören, z.B. Beweggründe, die zur Wahl des Themas geführt haben. Die
% unterstützenden Personen und Institutionen werden genannt.

\section{Vorwort}

\begin{displayquote}
	\itshape{}
	\ldots diese Nullen tatsächlich rätselhafte, unverständliche Dinger waren.
	\ldots So eine Null bestand im Grunde bloß aus zwei Kupferscheiben von der
	Größe einer Untertasse und einer Dicke von fünf Millimetern --- der Abstand
	zwischen den Scheiben betrug ungefähr vierzig Zentimeter. Außer diesem Abstand
	aber gab es nichts zwischen ihnen, absolut nichts, nur Leere. Man konnte die
	Hand in den Zwischenraum stecken, sogar den Kopf, wenn man übergeschnappt war
	--- nichts als Luft. Und doch musste was zwischen den Scheiben existieren,
	irgendeine geheimnisvolle Kraft, wenn ich recht verstehe, denn noch niemandem
	war es bisher gelungen, sie zusammenzudrücken oder auseinanderzuziehen.”
	(Arkadi und Boris Strugazki: Picknick am Wegesrand)
\end{displayquote}

Es ist spannend sich vorzustellen, wie das Leben in einer zweidimensionalen Welt
wäre. Man kann sich das vorstellen wie kleine Lebewesen auf der Tischfläche, wo
nur ihre eigene Ebene wahrnehmen können. Sie sehen nicht ausserhalb dieser
Ebene, sie können sich auch nur in ihrere eigenen, unendlichen zweidimensionalen
Raum bewegen. Könnten sie vielleicht einen Zeichen davon merken, dass rund um sie
herum ein grösserer Raum existiert?

Eines Tages lässt jemand einen Bleistift neben dem Tisch fallen, was durch die
Ebene der Lebewesen fällt. Einer der Tierchen wird Zeuge dieses Vorfalls: Er
sieht zuerst einen Kreis der immer grösser wird, zuerst ist es schwarz, dann
holzfarben. Dann sieht er einen roten Sechseck, und etwas später verschwindet
dies ganz. Das Phänomen ist unerklärbar, aber kurz. Er erzählt es seinen
Kameraden vergebens, niemand glaubt ihm.

Einige Tage später legt jemand eine
Gabel auf die Tischkante, so dass dessen Spitzen nicht auf dem Tisch sind. Diese
Spitzen krümmen sich aber nach unten, und gehen durch die Ebene wo unsere
Lebewesen leben. Dieses Phänomen haben sie alle genug Zeit um zu beobachten.
Wenn sie sich alle anstrengen, können sie die Gabel sogar etwas bewegen. Alle
beobachten gespannt wie die vier kleine metallene Objekte, die sichtbar von
nichts zusammengehalten werden, aber trotzdem immer gleichweit voneinander
bleiben, egal wie oder welchen sie bewegen.
\newline
\newline
Es hat mich immer beschäftigt, mir etwas vorstellen zu können, das eigentlich
recht unvorstellbar ist. Für mich sind vierdimensionale Räume genau so ein
Thema. Für meine Maturarbeit habe ich den kleinsten unvorstellbaren Raum
gewählt, den vierdimensionalen Raum, und darin einen gut bekannten, einfachen
Körper, den Würfel. Nur eine Kugel wäre einfacher gewesen, aber genau wie alle
zweidimensionale Schnitte einer dreidimensionalen Kugel Kreisflächen sind, sind
alle dreidimensionale Schnitte von vierdimensionalen Kugeln normale Kugeln.
\newline
\newline
Hier möchte ich mich bei meine Vater bedanken, der immer für mich da war, und
mir geholfen hat wenn ich stecken blieb beim Programmieren. Er hat mir ausserdem
geholfen die Technologien und Methoden kennen zu lernen, und die richtigen
auszuwählen. Ich bedanke mich bei meiner Mutter, wo mich ermutigt hat; und bei
meinem Bruder, der oft schlafen musste während ich noch im Zimmer am arbeiten
war. Ich möchte mich ausserdem bei meiner Begleitperson, Herr Pietro Gilardi,
bedanken, für seine Unterstützung und dass er die Aufgabe angenommen hat meine
Arbeit zu betreuen, nachdem meine vorherige Begleitperson die Schule verlassen
hat und mich nicht weiter betreuen konnte.


\section{Einleitung}

% Hier wird die Projektidee beschrieben und die Problemstellung erläutert.
% Wichtig ist auch die Eingrenzung des Projekts.

\subsection{Zielsetzung}

Die zweidimensionale Schnitte von dreidimensionalen Körpern kennen wir gut.
Schauen wir beispielsweise den Einheitswürfel an. Viele seiner Schnitte sind
quadratisch oder rechteckig. Wir finden aber auch schnell dreieckige Schnitte:
wir schneiden eins der Ecken ab. Etwas schwieriger ist es zu sehen, dass wir
auch fünf, und sechseckige Schnitte bekommen können. Wie sehen wohl verschiedene
vierdimensionale Schnitte aus? Diese Arbeit beschäftigt sich mit dem: es stellt
Schnitte mithilfe einer Computersimulation dar.


Ein wichtiges Ziel ist, dass man die dreidimensionale Resultate von den
Schnitten gut von allen seiten beobachten kann. Dass heisst, dass sie drehbar,
bewegbar, und verständlich gefärbt dargestellt werden.
% Auch ein wichtiges Ziel war, dass das Programm als internetseite erreichbar ist


\section{Hauptteil}

% Dieser Teil der Arbeit enthält die reflektierende Auseinandersetzung mit der
% eigenen Arbeit. Er wird in einzelne Kapitel und Unterkapitel eingeteilt. Hier
% kann auch die Dokumentation des Arbeitsprozesses erfolgen. In welcher Form die
% Dokumentation konkret erfolgen wird (separates Skizzenbuch, Arbeitsmappe etc.),
% ist zu Beginn des Prozesses mit der Betreuungsperson zu vereinbaren.

\subsection{Theorie}

\subsubsection{Wie stellen wir uns einen vierdimensionalen Würfel vor? Was ist ein vierdimensionaler Würfel?}

Um zu definieren, wie ein vierdimensionaler Würfel aufgebaut ist, werfe ich
einen Blick auf den Unterschied zwischen einem dreidimensionalen Würfel und einem
zweidimensionalen Würfel, und einem zweidimensionalen Würfel und einem
eindimensionalen Würfel. Ein- und zweidimensionale Würfel gibt es bekanntlich
nicht. Was am nächsten an einen zweidimensionalen Würfel kommt, ist ein Quadrat.

Wie mache ich einen Würfel aus einem Quadrat? Anfänglich liegt das Quadrat
einfach auf der Ebene $F(x, y) = 0$. Um daraus einen Würfel zu machen, dupliziere
ich das Quadrat, und bewege es entlang der neuen Koordinatenachse, bis die zwei
Quadrate gleich weit voneinander entfernt sind, wie die Seitenlänge eines
Quadrats ist. Nun verbinde ich die Ecken der Quadrate, die übereinander sind, es
wird zu einem Würfel.

Genau gleich können wir aus einem eindimensionalen Würfel ein Quadrat machen.
Jedes eindimensionale Objekt ist eine Strecke. So auch ein Würfel. Nehme ich
jetzt eine Strecke, setze es in einen zweidimensionalen Raum auf die Gerade
$F(x) = 0$, dupliziere die, und bewege diese zweite Strecke auf der neuen y Koordinate
bis die zwei Strecken so weit voneinander sind wie eine Strecke lang ist,  und
verbinde dann die Ecken, habe ich einen Quadrat.

So mache ich den Sprung auch eine Dimension höher. Ich nehme einen Würfel mit
Seitenlänge 1, auf der Hyperebene $F(x, y, z) = 0$. Ich nehme einen zweiten
Würfel und verschiebe ihn entlang der $w$-Achse um $1$. Nun verbinde ich alle
Ecken dieser Würfel. Dieses Objekt nenne ich einen vierdimensionalen Würfel.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{ma_diagrams/4dcube_repr.png}
	\caption{Vierdimensionaler Würfel, dargestellt durch zwei 3d Würfel mit verbundenen Ecken. Die cyanfarbene Kanten gehen durch die vierte Dimension}
	\label{fig:4d_repr}
\end{figure}

\subsubsection{Die definition eines vierdimensionalen Würfels}

Um einen vierdimensionalen Würfel zu definieren, müssen wir zuerst den
vierdimensionalen Raum definieren. Dies definieren wir ähnlich zu den zwei- und
drei dimensionalen Räumen:

\begin{equation*}
	\sysdelim..\systeme[][:]{
		\R^2 = \{(x1, x2)\ |\ x1, x2 \in \R\}:
		\R^3 = \{(x1, x2, x3)\ |\ x1, x2, x3 \in \R\}:
		\R^4 = \{(x1, x2, x3, x4)\ |\ x1, x2, x3, x4 \in \R\}
	}
\end{equation*}

Es ist einfach zu sehen, dass es auf den Fall einer beliebigen $n\in \mathbb{N}$
ausehnbar ist.


Eine Hyperebene ist folgendes: In einem n-dimensionalen Raum beschreibt es alle
Punkte, die durch einen Stützvektor und n-1 Richtungsvektoren beschrieben werden
können. Somit beschreibt es einen n-1 dimensionalen Raum innerhalb eines
n-dimensionalen Raumes.


Im folgenden beschäftigen wir uns mit vierdimensionalen Räumen. Die Koordinaten
schreiben wir als $(x, y, z, w)$. Unter einer Hyperebene verstehen wir die
dreidimensionalen Hyperebenen des vierdimensionalen Raumes.
\newline
\newline
Definieren wir nun Würfel in verschiedenen Dimensionen:
\begin{itemize}
  \item Der eindimensionale kanonische Würfel: $\{x\in\R\ |\ -1\leq x\leq 1\}$

  \item Der zweidimensionale kanonische Würfel: $\{x, y\in\R\ |\ -1\leq x, y\leq 1\}$

  \item Der dreidimensionale kanonische Würfel: $\{x, y, z\in\R\ |\ -1\leq x, y, z\leq 1\}$

  \item der vierdimensionale kanonische Würfel:  $\{x, y, z, w\in\R\ |\ -1\leq x, y, z, w\leq 1\}$
\end{itemize}
Wir merken, dass im Fall des dreidimensionalen Würfels die Ecken genau die Punkte
sind, wo bei allen drei Koordinaten die eine Ungleichung gleich ist. Das heisst,
dass die Koordinaten $-1$ oder $1$ sind. Solche Tripel hat es $2^3 = 8$, genau so
viel, wie wir erwartet haben. Die Kanten bekommen wir auf folgender Weise: Aus
den drei Koordinaten fixieren wir beliebige zwei auf eines der Grenzwerte (auf
$-1$ oder $1$), und der andere gleitet über den $(-1, 1)$ intervall. Zwei Koordinaten
aus drei auszuwählen, und dann für die zwei Koordinaten alle grenzwert
Kombinationen durchgehen ergibt $3\times 2\times 2 = 12$ möglichkeiten, genau so
viele Kanten hat ein Würfel. Bei den Flächen gehen wir ähnlich vor, aber jetzt
fixieren wir nur eines der Koordinaten auf $-1$ oder $1$. $3\times 2=6$
möglichkeiten hat es da, so viele Flächen hat ein Würfel.


Was ist der Fall bei einem vierdimensionalen Würfel?


Eine Ecke nennen wir wieder eine Ecke, falls alle Koordinaten entweder $-1$ oder
$1$ sind. Daraus bekommen wir $2\times 2\times 2\times 2 = 16$ Ecken. Kanten,
also eindimensionale Seiten bekommen wir mit drei fixierten Koordinaten. Dies
ergibt $4 \times 2\times 2\times 2 = 32$ Kanten. Die Anzahl zweidimensionaler
Seiten ist ${4 \choose 2} \times 2\times 2= 24$. Diese sind weiterhin Quadrate,
genau wie in der eins tieferen Dimension. Vierdimensionale Würfel haben auch
dreidimensionale Flächen. Diese bekommen wir, indem wir nur eines der Koordinaten
bei $-1$ oder $1$ fixieren. Fixieren wir beispielsweise die letzte Koordinate,
bekommen wir den dreidimensionalen kanonischen Würfel, angeschaut aus einer höheren
Dimension. Die dreidimensionalen Seiten sind alles reguläre Würfel. Es hat
$4\times 2 = 8$ davon.


\subsubsection{Schnittkörper eines 4d Würfels mit einer 3d Hyperebene}


Der Schnittkörper eines 4d Würfels und einer 3d Hyperebene ist ein maximal
dreidimensionales Volumen. Es ist weniger wie dreidimensional in entartetten
Fällen, beispielsweise wenn die Hyperebene eine Ecke, Kante, oder
zweidimensionale Seite nur knapp berührt.

Um einen Weg zu finden diesen Schnittkörper zu berechnen, schauen wir uns zuerst
das Problem im dreidimensionalen Raum an. Wir sehen dass wir im Normalfall die
Schnittfläche eines 3d Würfels und einer 2d Ebene als konvexe Hülle der
Schnittpunkte der Ebene mit den Kanten des Würfels bekommen können (Figure~\ref{fig:3d-intersection}).

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{ma_diagrams/cube_intersect.png}
	\caption{Schneidung eines 3d Würfels mit einer 2d Ebene. Siehe wie die
  Schnittfläche die konvexe Hülle der Schnittpunkte von der Ebene mit den Kanten
  des Würfels ist. }
	\label{fig:3d-intersection}
\end{figure}

Im Normalfall hat es maximal einen Schnittpunkt mit jeder beliebigen Kante und
der Schnittebene.

Es hat aber einige entartende Fälle. Beispielsweise wenn einige Kanten vom
Würfel komplett auf der Schnittebene liegen.

Für diese Fälle bleibt der Algorithmus korrekt, denn wir nehmen einfach beide
Enden der gegebenen Kante, und betrachten diese Punkte als Schnittpunkte mit der
Schnittebene und der Kante. (Es ist einfach zu sehen, dass alle Punkte zwischen
diesen zwei in der konvexen Hülle sind von jedem Set von Punkten wo beide
beinhaltet).

Wir beweisen, dass der gleiche Algorithmus anwendbar ist, wenn wir einen 4d Würfel
mit einer 3d Hyperebene schneiden: der Schnittköper wird die konvexe Hülle von
den Schnittpunkten der Kanten des Würfels und der Hyperebene im Normalfall.

\begin{lemma}
	\label{lemma:intersection}
	Im Normalfall wird das Resultat eines Schnittes von einer zweidimensionalen
	Kante und eines dreidimensionalen Hyperebene ein einzelner Punkt.
\end{lemma}


\begin{proof}
Im 4d Raum existiert für jede 3d Hyperebene ein Vector $\overrightarrow{v}$, das
orthogonal zur Ebene ist. Jede Linie dass nicht orthogonal zu $v$ ist, kann nur
einen Schnittpunkt mit der Ebene haben. Wenn es mindestens 2 hätte, $x_1$ und
$x_2$, dann wäre $\overrightarrow{x_2 - x_1}$ auf der einen Seite orthogonal zu
$\overrightarrow{v}$ weil die Hyperebene orthogonal zu $\overrightarrow{v}$ ist,
aber auf der anderen Seite nicht orthogonal, weil wir angenommen haben, dass die
Linie nicht orthogonal zu $\overrightarrow{v}$ ist.
\end{proof}

\begin{lemma}
  Im Normalfall ist der Schnitt von einer 3d Seite eines 4d Würfels und einer 3d
  Hyperebene zweidimensional.
\end{lemma}

\begin{proof}
Eine 3d Seite eines 4d Würfels ist ein 3d Würfel. Gemäss
Lemma~\ref{lemma:intersection} sieht der Schnitt der Kanten wie
Figure~\ref{fig:3d-intersection} aus. Der komplette Schnitt ist die konvexe
Hülle dieser Punkte. Es ist eindeutig dass sie einen mindestens
zweidimensionalen Raum spannen. Im Normalfall müssen sie auf der selben 2d Ebene
liegen. Um das zu beweisen, nehmen wir an, dass sie nicht auf der selben 2d
Ebene liegen. Das würde heissen, dass wir einen Punkt finden können auf einer
Kante, das wir via lineare Kombination von den anderen drei Punkten erreichen
können. Das heisst, dass wir 2 Punkte auf der gleichen Kante haben, dass im
dreidimensionalen Raum ist, und das ist nicht ein Normalfall gemäss
Lemma~\ref{lemma:intersection}.
\end{proof}

Das heisst, dass im Normalfall die äussere Oberfläche des Schnittes von einem 4d
Würfel und einer 3d Hyperebene eine Union von 2d Flächen sein wird, welches wir
bekommen indem wir die 3d Seiten mit der 3d Hypereben schneiden, und das ist was
wir beweisen wollten.

\subsubsection{Rechenalgorithmus}

Um einen praktischen Algorithmus implementieren zu können, müssen wir eine
Repräsentation von einem 4d Würfel im 4d Raum finden, dass wir verstehen und
nachvollziehen können. Beachten wir, dass schon die Aufzählung der 2d Seiten nicht trivial ist.

Um mit der Komplexität umzugehen, implementieren wir folgenden Algorithmus um
den Schnitt von einem 4d Würfel und einer 3d Hyperbene zu bestimmen:

\begin{enumerate}
  \item Wir wenden eine isometrische Transformation und eine einheitliche
  Skalierung an, dass den Würfel in den kanonischen Würfel transformiert.
  \item Wir transformieren die 3d Ebene mit der gleichen Transformation.
  \item Wir schneiden den kanonischen Würfel mit der transformierten Ebene.
  \item Wir wenden die Inverse der Transformation am resultierenden Körper an.
\end{enumerate}

Diese Vorgehensweise erlaubt uns eine einfache Implementation des
Schneidealgorithmusses.

% \subsection{Spezifikation}

% \subsubsection{User journeys}

% \begin{enumerate}
%   \item Die dargestellte Welt verändern indem man den input file bearbeitet.
%   \item Das Programm starten mit einem spezifischen input file.
%   \item Die aktuelle Parameter der 3d Hyperebene kennen.
%   \item Die aktuelle Kameraposition und Winkel im 3d resultierenden Schnitt
%   kennen.
%   \item Die Kamera drehen und bewegen im resultierenden 3d Schnitt.
%   \item Die 3d Hyperebene drehen und bewegen.
% \end{enumerate}

% \subsubsection{Functional requirements}

% \begin{enumerate}
%   \item Die Kamera kann bewegt und gedreht werden mit den standard
%   Tastenbelegung für dreidimensionale Spiele und der Maus.
%   \item Die Hyperebene kann senkrecht zu sich selber bewegt werden, und ist
%   drehbar entlang den drei Dimensionsachsen seines momentanen Referenzrahmen.
%   \item Die Parameter der Hyperebene, und die Position und Richtung der Kamera
%   werden auf dem Bildschirm angezeigt.
% \end{enumerate}

\subsection{Design}

% \subsubsection{Modell}

% \begin{figure}[H]
% 	\centering
% 	\includegraphics[scale=0.3]{mock.png}
% 	\caption{Skizze der Applikation.}
% 	\label{fig:mock}
% \end{figure}

% Figure~\ref{fig:mock} zeigt wie die Applikation aussehen wird. In der Mitte
% sehen wir den Schnitt des Würfels und der Hyperebene. In der unteren rechten
% Ecke sehen wir eine Bildschrimanzeige, das die Position und Orientation der
% Hyperebene und der Kamera anzeigt.

\subsubsection{Steuerungsmöglichkeiten}

\begin{itemize}
	\item Steuerung der Kamera
	      \begin{itemize}
		      \item Bewegen mit der Tastatur (left, right, forward, backward, up, down).
		      \item Drehen mit der Maus (left, right, up, down).
	      \end{itemize}
	\item Steuerung der Hyperebene:
	\item Vorwärts und Rückwerts entlang des Normalvektors verschieben.
	\item Drehen entlang den Dimensionsachsen des Referenzrahmens.
\end{itemize}

\subsubsection{Konfigurations Format}

% ! not done
\begin{itemize}
  \item Eine einfache textbasierende konfigurations Format.
  \item Beinhaltet eine Spezifikation einer Hyperebene, und eine beliebige
  Anzahl von Spezifikationen für Würfel.
  \item Alle Spezifikationen sehen folgendermassen aus: <Was> <Zahlen>
  \item Leerzeichen, einschliesslich der Leertaste und Zeilenumbrüche können
  beliebig verwendet werden.
  \item Hyperebenen Spezifikation: HYPERPLANE <Ursprung> <3 orthogonale
  Vektore>\newline
  Die erste 4 Zahlen zeigen zum Ursprung, die verbleibenden 3$\times$4 Zahlen sind die
  drei Einheitsvektoren. Sie müssen orthogonal sein damit das Programm richtig
  funktioniert.
  \item Würfelspezifikation: CUBE <Grösse> <Ursprung> <4 orhtogonal
  vectore>\newline Die Grösse ist eine einzelne Zahl, der Ursprung besteht aus
  vier Zahlen die als Vektor zum Ursprung zeigen, und die verbleibenden 3$\times$4
  Zahlen beschreiben die Einheitsvektoren in den Richtungen der Würfelseiten.
\end{itemize}

\subsection{Bedienungsanleitung}

\subsubsection{Installation}

\begin{itemize}
  \item Für Linux, lade den Quellcode herunter, installiere die
  dev dependencies, kompiliere es.
  % explain compilation process or include a zip file too
  \item Für Windows, lade den Zip-File von der Github release page herunter.
\end{itemize}

\subsubsection{Den Programm mit einer gegebenen Konfiguration starten}

\begin{itemize}
  \item Finde den installierten \code{configs} Ordner.
  \item Finde die installierte Binärdatei.
  \item Lasse die Binärdatei von einem Command-Terminal laufen, und gebe den
  konfigurations File als einzigen Parameter an.
\end{itemize}

\subsubsection{Das Programm steuern}

\begin{itemize}
	\item Die Kamera bewegen: A --- links, D --- rechts, W --- forwärts, S --- rückwärts, Shift --- Hoch, Ctrl --- Runter
	\item Die Kamera drehen: Maus
	\item Die Hyperebene auf seinem Normalvektor verschieben: R --- positive Richtung, F --- negative Richtung
	\item Die Hyperebene drehen: O, P, \lbrack und L, ö, ä. (Auf einer
	Deutsch-Schweizer Tastatur. Auf anderen Tastaturen sollten die Tasten
	funktionieren, wo auf dem Platz von ö oder ä sind)
\end{itemize}

\subsection{Entwicklung}

\subsubsection{Tools, Frameworks}

\begin{itemize}
  \item Programming language: C++
	\item Cross-platform windowing library with OpenGL support: GLFW\@.
	\item Drawing: OpenGL
	\item OpenGL loader: GLEW
	\item Build system: CMake
\end{itemize}

\paragraph{C++}
C++ ist meine präferierte Computersprache. Alles Programmcode das ich
geschrieben habe ist in dieser Sprache, mit ausnahme der Shaderprogramme, die in
glsl geschrieben werden müssen.



\paragraph{GFLW}
GLFW ist eine Library die Anwendungsfenster und Eingabe über Maus und Tastatur
verwaltet. Mithilfe von GLFW ist es möglich für uns einen Fenster zu öffnen mit
dem Programm, um eine Oberfläche zum Zeichnen zu erhalten.

\paragraph{OpenGL}
OpenGL ist im Prinzip was uns erlaubt mit der Graphikkarte zu komunizieren. Wir
rufen OpenGL Funktionen, und schicken damit unsere Punkte an die Grafikkarte.
Wir schicken ausserdem unser Schattierungsprogramme an die Grafikkarte. Die
Grafikkarte benutzt diese Programme dann in der richtigen Reihenfolge um zu
berechnen welche Pixel auf dem Bildschirm genau welche Farbe haben sollen.

\paragraph{GLEW}
OpenGL hat eine API (Das heisst Funktionen, die man benutzen kann im eigenen
Code) die Öffentlich ist. Aber je nach Graphikkarten Hersteller und
Operationssystem sind diese Funktionen anderst implementiert. Ausserdem gibt es
viele OpenGL Versionen, und manchmal möchte man, dass ein Programm auf mehreren
Versionen funktioniert. Im Normalfall werden die Funktionen einer API während
der Compilation in das eigene Programm compiliert. Mit OpenGL aber wird nur eine
sehr kleine Anzahl der Funktionen direkt reincompiliert, viele der Funktionen
müssen abgefragt werden. Somit kann man nach einer Funktion `Zeichnen' fragen,
und falls diese auf mehreren OpenGL Versionen existiert, funktioniert das
Programm auf alle diesen Versionen. Damit man dieses Abfragen nicht selber
machen muss, exisitert GLEW\@. GLEW erledigt dies ganz automatisch, man muss nur
einige Parameter angeben, und dann Funktioniert es von alleine.

\subsubsection{Die Funktionsweise und das Zusammenspiel der Libraries, der
Graphikkarte und das Operationssystems}\label{sssec:libraries} Ich habe die
Libraries, die ich benutzt habe, oben beschrieben. Hier erläutere ich, wie genau
sie funktionieren. Mit einem Programm ein Applikationsfenster zu öffnen und zu
benutzen ist ganz einfach mit Libraries, die im Hintergrund alles komplizierte
automatisch lösen. Aber diese haben immer sehr viele Einschränkungen. Wenn man
wirklich frei sein will zu tun und zu lassen was man will, muss man ganz vieles
selber lernen und machen.

Aus diesem Grund habe ich mich dafür entschieden zu lernen, wie man mit OpenGL
umgeht. OpenGL ist eines der meistverbreiteteten API's für zwei- und
dreidimensionale Vektorgraphiken, und ich war mir sicher, es macht Sinn das zu
lernen.

Mit OpenGL lädt man Daten auf die Grafikkarte. GLEW dient dabei wie ein
Übersetzer; es macht eigentich nichts anderes wie unsere Funktionsaufrufe and
die richtigen Funktion zu binden. In unserem Fall lädt man eine Menge von
Punkten in einem 3d Raum (repräsentiert durch Vektoren) auf die Grafikkarte.
Ausserdem lädt man die Schattierungsprogramme auf die Grafikkarte. Alles andere,
also die Berechnungen und die Verwaltung des Bildschirms, geschieht `von
alleine'. Es wird von der Grafikkarte übernommen, und ist nicht unsere
Verantwortung. Die Schattierungsprogramme, sofern wir sie in den richtigen Ort
geladen haben, verändern und interprätieren unsere Daten, sodass aus Punkten und
Farben und Vektoren eine Menge von Pixel entstehen. 

OpenGL selber ist aber nur ein Werkzeug um mit der Grafikkarte zu komunizieren.
Um ein Fenster zu öffnen und Tastendrücke zu erkennen und verwenden im Programm
brauche ich auch eine Schnittstelle mit dem Operationssystem. Dafür verwende ich
GLFW\@. GLFW (Graphics Library Framework) hilft bei der Kommunikation mit dem
Operationssystem. Mithilfe von GLFW kann ich das Applikationsfenster erstellen
und verwalten, Tastendrücke wahrnehmen und die Mausbewegung benutzen.

Was noch nicht ganz klar ist, wie die Grafikkarte weiss, wo genau die
berechneten Pixel hingehören. Dies ist so gelöst, dass wir durch GLFW einen
sogenannten Context beim Erstellen des Fensters erhalten. Wenn wir die Daten und
Programme an die Grafikkarte schicken, schicken wir auch die Information,
welchen Context wir benutzen.

Je nach Operationssystem bekommt GLFW so einen Context auf unterschiedlicher
Weise für uns. Auf Windows werden die Fenster vom Operationssystem verwalten.
Das heisst, das GLFW mithilfe des Operationssystems ein Fenster erstellt, was
widerum auf der Grafikkarte einen Context erstellt, und an GLFW die Nummer des
Contextes auf der Karte mitteilt. Auf Linux, zumindest auf der Distribution die
ich benutze, gibt es einen sogenannten Compositor. Der sorgt dafür, dass alle
Fenster richtig funktionieren, macht das man bei transparenten Fenster das
sieht, was unter dem Fenster ist, und verwaltet allgemeint alles was Fenster
angeht. Somit spricht GLFW nicht nur mit dem Operationsystem, sondern auch mit
dem Compositor. Der Compositor erstellt durch OpenGL einen Context und gibt dann
auch die Nummer des Contextes an GLFW zurück.


\subsubsection{Meilensteine}

\paragraph{Meilenstein 1: Ein 3d Würfel dargestellt, mit Navigation}

\subparagraph{Key results}

\begin{itemize}
	\item Der 3d Würfel ist gerendert.
	\item Das Bewegen des Kameras ist möglich mit der Tastatur und der Maus.
\end{itemize}

\subparagraph{Value}

Wir haben eine Arbetisumgebung aufgebaut, und haben ein Verständniss für die
Frameworks und Libraries erarbeitet.

% We bootstrapped the working environement and built an understanding of the core
% frameworks and libraries.

\subparagraph{Prozess}
Dieser Meilenstein sieht nicht sehr schwierig aus, aber war eines der
zeitaufwändigsten Teile des Projekts. Ich habe zuerst aus einem Buch und dem
Internet gelernt, wie OpenGL funktioniert, und was man für Libraries braucht.
Ich musste zuerst lernen, wie diese zusammenspielen. Erst dann konnte ich einen
einzelnen blauen Punkt auf dem Bildschirm erscheinen lassen. Dann konnte ich
anfangen einen Würfel darzustellen. Hier war die grösste Schwiereigkeit den Code
richtig zu strukturieren. Ich habe mir hier überlegt, was für Datenstrukturen ich
brauchen werde, und was ich in Klassen abstrahieren möchte. 

\paragraph{Meilenstein 2: Der Schnitt eines zentrierten, kanonischen 4d Würfels
mit einer verstellbaren und beweglichen Hyperebene wird dargestellt.}

\subparagraph{Key results}

Ein C++ Programm, dass

\begin{itemize}
  \item den Schnitt eines zentrierten, kanonischen 4d Wüfel mit einer arbiträren
  Hyperebene berechnet.
  \item diesen Schnitt als dreidimensionales Objekt rendert.
  \item die Parameter der Hyperebene interaktiv ändern kann.
  \item den gerenderten Schnitt bei Änderungen der Hyperebene in Echtzeit anpasst.
  \item weiterhin im dreidimensionalen Raum navigieren kann wie im vorherigen Meilenstein.

	% \item computes the intersection of a 4d unitcube with an arbitrary hyperplane
	% \item renders this intersection as a three dimensional object
	% \item can alter the parameters of the hyperplane interactively
	% \item adjusts the rendered object in real time to the changes of the hyperplane
	% \item can still navigate in the three dimensional world like in the previous milestone
\end{itemize}

\subparagraph{Value}

Es zeigt sich dass die Theorie für die Berechnung des Schnittes korrekt ist. Wir
erhalten einen ersten Eindruck vom 4d Würfel.

% The theory for the intersection is prooven to work. First impressions of the 4d cube can be aquired.

\subparagraph{Prozess}
Hier habe ich zuerst lange nichts programmiert, sondern habe mir mit Papier und
Stift überlegt, wie das funktionieren soll. Ich habe beschlossen, dass ich die
Hyperebene mit zwei vierdimensionalen Vektoren repräsentiere. Eins ist ein
Normalvektor, und der Andere beschreibt die Verschiebung der Hyperebene vom
Ursprung. Hier habe ich mir auch ausgedacht, wie der Algorithmus funktionieren
soll, sodass ich einen 3d Schnittkörper erhalte. Ich habe schnell einen
Algorithmus erfunden, um die Eckpunkte des Schnittkörpers zu finden, aber das
hat noch lange nicht alles gelöst. Um einen Körper mit OpenGL darzustellen muss
man es nämlich in Dreiecke zersetzen, und dann diese Dreiecke an OpenGL
schicken. Dafür musste ich wissen welche der Ecken benachbart sind. Dies war
keine triviale Aufgabe. Ich dachte zuerst daran einem klassischen Algorithmus
für dreidimensionale konvexe Hüllen zu implementieren. Dies wäre aber recht
komplex und zeitaufwändig gewesen. Darum habe ich mir lieber eine einfacher
implementierbare Methode überlegt, die beim Schneiden des Würfels die
Information ausnutzt, auf welcher 2d Seite sich ein Schnittpunkt befindet, um zu
bestimmen welche Punkte benachbart sein können. Der genaue Algorithmus, wie die
Dreiecke zusammengestellt werden, folgt später.

\paragraph{Meilenstein 3: Sichtbarkeitseffekte}

\subparagraph{Key Results}

Objektschattierung und Beleuchtung wird implementiert.

\subparagraph{Value}

Der Programm erlaubt uns mit Parametern zu experimentieren, und verschiedene
Formen und Gestalten von Schnitten des 4d Würfels kennen zu lernen.

Mit den Lichteffekten und der Schattierung wird das gerenderte Bild einfacher zu
sehen und zu verstehen für den Benutzer. Jetzt erst sind die Kanten und Ecken
sichtbar. Ohne Schattierung konnte man nur die Umrisse sehen, und die Kanten und
Ecken durch Bewegung erahnen.

% The program allows us to experiment with parameters, form a visual idea about
% various projection shapes of the 4d cube and use it as an experiment and
% development platform for subsequent milestones.

% With object shading and lighting the rendered picture will be more easily understood by the user.

\subparagraph{Prozess}
Damit man überhaupt einen Punkt erscheinen lassen kann, bracht man sogenannte
Schattierungsprogramme. OpenGL funktioniert so, dass jeder Punkt eine sogenannte
Rendering Pipeline durchläuft. Vereinfacht sieht das so aus, dass zuerst jeder
Punkt durch den Vertex Shader geht, dann alle Primitive (in unserem Fall
Dreiecke, aber es könnten auch Linien sein) durch den Tesselation Shader und dem
Geometry Shader gehen. Dann geschieht die Rasterization, das heisst, dass jetzt
die einzelnen Pixel auf dem Bildschirm berechnet werden. Schlussendlich geht
jeder Pixel noch durch den sogenannten Fragment Shader. Uns interessiert nur der
Vertex Shader und der Fragment Shader. Für dieses Projekt ist es nicht nötig die
anderen zu benutzen. 

Wie man solche Shattierungsprogramme (Shader) schreibt, habe ich schon im
Verlauf des Arbeitsprozesses gelernt. Doch erst in diesem Schritt habe ich genau
lernen und verstehen müssen, wie man sie am besten benutzt, was es für tricks
gibt. Bis zu diesem Moment habe ich nur primitive Shader gehabt (Beispielsweise
habe ich nur jedem Punkt eine Farbe gegeben, und darauf vertraut, dass während
dem Rasterizationsverfahren durch Interpolation ein Farbverlauf entstehen wird
auf dem Würfel). Jetzt habe ich aus dem OpenGL Buch gelernt, wie man Lichteffekte
haben kann, indem man Informationen wie den Ursprung des Lichtes,
Materialeigenschaften, Lichtintensität und Farbe, und weiteres an die Shader
schicken kann, und mit Formeln so die richtige Schattierung für jeden Pixel
ausrechnen kann.

\paragraph{Meilenstein 4: Der Schnitt eines arbiträren 4d Würfels}

\subparagraph{Key results}

Der Würfel ist nicht mehr zwingend zentriert beim Ursprung. Er kann sich jetzt
an einem arbiträren Ort im 4d Raum, mit einer arbiträren Drehung befinden. Dies
ist hier aber erst nur im code beeinflussbar, man kann den Würfel nicht bewegen.


\subparagraph{Value}

Wir haben ein Skelett vom Kern des Programms.

% We have a skeleton of the core of the code with end to end functionality.

\paragraph{Meilenstein 5: Ein Format, dass den Aufbau einer Welt beschreibt}

\subparagraph{Key results}

\begin{itemize}
  \item Ein Fileformat wird definiert, dass 4d Objekte im Raum beschreibt.
  \item Ein Parser ist implementiert.
\end{itemize}

\subparagraph{Value}

Wir sind bereit das Endprodukt zusammenzustellen.

\paragraph{Meilenstein 6: Die Renderung einer Welt}

\subparagraph{Key results}

Das Programm can eine Welt, definiert durch einen configurations File, rendern.
Die Schnitt-Hyperebene und Kamera sind weiterhin dreh und bewegbar. Auf einer
HUD (Heads-Up Display) werden die Parametern der Hyperebene und der Kamera
präsentiert.

% Program that can render a World described a config file, allows moving the
% projection plane as well as the camera in the 3d world. Provides feedback of
% projection and camera position in a HUD.

\subparagraph{Value}

Dies ist das erwartette Endprodukt von der ursprünglichen Projektbeschreibung.

% This is a minimum viable solution of the original project description.

\subsubsection{Die wichtigste Module im Programm}
\paragraph{Die \code{main()} Funktion} Die \code{main()} Funktion ist die
Funktion die gestartet wird wenn das Programm startet. Es stellt die
Ausgangswerte aller Module ein und startet GLEW und GLFW\@. Nacher geht es in
eine unendliche Schleife bis das Fenster geschlossen wird. Ein Zyklus in dieser
Schleife nennen wir einen Tick. In deinem Tick geschieht folgendes:
\begin{itemize}
  \item Falls sich die Fenstergrösse verändert hat, wird dies im Renderer
  angepasst.
  \item Der Renderer rendert ein Bild.
  \item Alle Tastatur- und Mausevente werden abgefragt, und vom Inputmodul
  gehandhabt.
  \item Es wird ausgerechnet wie viel Zeit verstrichen ist seit dem letzen Tick.
  \item Die \code{tick()} Funktion vom Kameramanager wird gerufen.
  \item Die \code{tick()} Funktion vom Hyperebenmanager wird gerufen.
\end{itemize}

Die zwei \code{tick()} Funktionen erhalten die verstrichene Zeit als
Parameter, damit sie ausrechnen können was sich wie viel bewegen muss. Sonst
kann es vorkommen, das die Kamera schneller ist falls der Computer schneller
ist, da mehr Ticks pro Sekunde gemacht werden können.

\paragraph{Der Intersektor}
Die Aufgabe des Intersektors ist das Schneiden von einem kanonischen Würfel mit
einer 3d Hyperebene.

4d Würfel haben 3d und 2d Seiten. In diesem Abschnitt werde ich mit einer Seite
immer eine 2d Seite meinen.

\subparagraph{Die Nachbarschaftsverhältnisse der Seiten}
Jede Kante im Würfel ist Teil von drei Seiten. Diese drei Seiten nennen wir
benachbart. 

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{ma_diagrams/3sides_per_edge1.png}
	\caption{Drei benachbarte Seiten}
	\label{fig:neigh1}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{ma_diagrams/3sides_per_edge2.png}
	\caption{Drei benachbarte Seiten}
	\label{fig:neigh2}
\end{figure}
Zuerst erstellen wir manuell eine Liste der Kanten. Für die Kanten
rechnen wir dann alle Seiten aus, die diese Kante beinhalten. Dies geschieht nur
ganz am Anfang vom Programm, bevor das erste Bild erscheint. Die Kanten sind
repräsentiert von zwei Vektoren, wo jeweils die zwei Endpunkte der Kanten
beschreiben. Bei der Vorberechnung geben wir jeder Seite eine
Identifikationszahl. Wir müssen nur wissen, welche Seite zu welcher Kante
gehört, aber brauchen für den Algorithmus keine weitere angaben einer Seite.

\subparagraph{Das Schneiden der Kanten}
Nun schneiden wir alle Kanten mit der Hyperebene. Dabei erhalten wir entweder
null, ein oder zwei Ergebnisse. Keine Ergebnisse, wenn die Kante ganz ausserhalb
der Hyperebene liegt, ein Ergebniss falls die Kante die Hyperebene kreuzt, und
zwei Ergebnisse, falls die Kante mit der Hypereben in einer Ebene liegt. In
diesem letzten Fall würde es eigentlich unendlich viele Resultate geben, aber
wir nehmen statt dem die zwei Enden der Kanten, da wir schlussendlich nur die
Punkte brauchen, die die konvexe Hülle des Volumens ausmachen. Das schneiden ist
trivial; Wir schauen wir die Distanz $d(A)$ zwischen Punkt A und der Hyperebene, und
die Distanz $d(B)$ zwischen Punkt B und der Hyperebene an. Falls $d(A)
\cdot d(B) > 0$ dann sind beide auf der gleichen Seite der Hyperebene,
und es gibt keinen Schnittpunkt. Falls $d = 0$ für eines der Punkte, wird dieser
Punkt als Schnittpunkt akzeptiert. Falls $d(A) = 0 \land d(B) = 0$ muss die
Kante auf der Hyperebene liegen, somit geben wir beide Endpunkte A und B
zurück. Ansonsten berechnen wir aus dem Verhältniss der beiden Distanzen wo auf
der Kante der Schnittpunkt ist, und geben das zurück. So bauen wir eine Liste
mit allen Schnittpunkten auf. Gleichzeitig bauen wir eine Datenstruktur auf, die
für jede Seite eine Liste von Schnittpunkten beinhaltet auf. Dies ist ganz
einfach, da wir vom Schnittpunkt den wir gerade gefunden haben immer wissen zu
welcher Kante es gehört, und wir schon im Voraus berechnet haben welche Seiten
welche Kanten beinhalten. Sobald ein Schnittpunkt gefunden wird, wird es bei
allen 3 Seiten die dessen Kante beinhalten abgespeichert als Schnittpunkt auf
der Oberfläche der Seite.

Während diesem Prozess rechne ich auch den Durchschnitt aller Schnittpunkte aus.
Dies wird sich innerhalb des Lösungskörpers befinden, und wird sich als
Hilfreich erweisen um Normalvektore zu finden die gegen Aussen zeigen.

% explain why
Zwei Schnittpunkte die sich auf der gleiche Würfelseite befinden, werden im
entstehenden Schnittvolumen immer eine gemeinsame Kante haben. Aus diesem Grund
können wir eine Liste von Nachbarpunkten für jeden Schnittpunkt aufbauen aus der
Datenstruktur die für jede Seite die Punkte auf dessen Oberfläche beinhaltet.

\subparagraph{Die Zusammensetzung der konvexen Hülle aus Dreiecken}
Wir könnten mit einer einfachen Tiefensuche alle Dreiecke finden, wo zwei Kanten
auch Kanten des Schnittvolumens sind. Wir machen eine Tiefensuche auf dem
Nachbarschaftsgraph, behalten immer die vorherigen zwei Punkte im Kopf, und
immer wenn wir zu einem Punkt gelangen zeichnen wir das Dreieck mit den
vorherigen 2 Ecken. Das habe ich zuerst auch getan. Es treten zwei Probleme auf:

\begin{itemize}
  % insert hexagon with hole
  \item
  \begin{description}
    \item[Löcher in der Oberfläche] Wenn man eine Fläche hat mit mehr als 4
    Ecken, und die Dreiecke auf dieser Weise zeichnet, gibt es einen Loch in der
    Mitte. Das ist einfach zu sehen auf der Abbildung~\ref{fig:hole}. Die Fläche
    kann nicht durch Dreiecke abgedeckt sein, wo nur Punkte beinhalten die
    benachbart sind. Es braucht auch Dreiecke, die aus einem Punk, und zwei
    Punkten wo auf der gegenüberliegenen Seite sind bestehen.
    \end{description}
    \begin{figure}[H]
      \centering
      \includegraphics[scale=0.15]{ma_diagrams/convex_hole.png}
      \caption{Das Loch das mit dem gierigen Algorithmus entsteht}
      \label{fig:hole}
    \end{figure}
  
  \item
  \begin{description}
    \item[Z-Fighting] Wenn zwei Objekte und die Kamera in einer Linie sind,
    verdeckt das eine Objekt das andere mindestens zum Teil. OpenGL geht damit so
    um, dass im Verlauf des im Abschnitt~\ref{sssec:libraries} beschriebenen Rendering
    Pipelines OpenGL doppelte Pixel aussortiert, und immer die näher zu der Kamera
    behält. Da OpenGL aber mit Gleitkommazahlen arbeitet, die eine kleine aber
    existente ungenauigkeit aufweisen, kommt es so das fallst zwei Flächen sehr
    genau aufeinanderliegen, es sehr zufällig ist welches der Flächen behalten,
    und welches weggeworfen wird. Dies führt zu einem vibrierenden Effekt: Wenn
    sich das Bild bewegt, ist bei jedem der etlichen Bilder pro Sekunde ganz
    zufällig eines der Flächen oben.

    Wenn wir so wie beschrieben die Dreiecke zeichnen, dann wird wie man in der
    Abbildung sieht, ein gewisser Teil immer überlappen. Dies führt zu unschönem
    Z-Fighting.
  \end{description}
\end{itemize}

Um vorläufig eines der Probleme zu beheben, habe ich einfach alle mögliche
kombinationen mit drei Schnittpunkten genommen, und sie als Dreieck gerendert.
Das löste natürlich das Problem von den Löchern. Es gab aber noch viel mehr
Z-Fighting, da noch viel mehr Flächen überlappten.

Ab hier nenne ich die gefundenen Schnittpunke Ecken oder Eckpunkte. Sie sind
nämlich die Ecken des Lösungsobjekts.

Zuerst dachte ich daran, einen Algorithmus für dreidimensionale konvexe Hüllen zu
implementieren. Diese sind aber sehr komplex, und ich habe gedacht das ich mir
sicher etwas einfacheres überlegen kann. So bin ich auf folgenden Algorithmus
gestossen:

Wenn ich ein Dreieck auf einer Fläche vom Lösungsobjekt habe, wo zwei der drei
Kanten auch Kanten des Lösungsobjekts sind, kann ich diese ganze Fläche des
Lösungsobjekts mit Dreiecken belegen, ohne Überlappen oder Löcher. Das
Funktioniert folgendermassen: Ich merke mir den Normalvektor des Dreiecks, das
ausserhalb des Lösungsobjekts zeigt. Um dies zu berechnen benutze ich den
Durchschnitt aller Ecken des Lösungskörpers, wo ich schon berechnet habe als ich
alle Ecken berechnet habe. Ich nehme eines der Punkte wo nicht in der Mitte ist
als Ausgangspunkt. Der mittlere Punkt ist der Punkt, wo beide andere Punkte als
Nachbar hat. Falls alle drei Punkte diese Eigenschaft besitzen, ist die ganze
Fläche nur ein Dreieck, da die drei Punkte durch drei Kanten des Lösungsobjekts
verbunden sind. Dann bricht der Algorithmus ab. Ansonten habe ich jetzt einen
Ausgangspunkt, einen mittleren Punkt, und einen Endpunkt. Ich gehe jetzt alle
Nachbarn vom Endpunkt durch. Ich kontrolliere immer, ob das Dreieck, das durch
den Augangspunkt, dem Endpunkt, und dem neuen Punkt gebildet wird, den gleichen
Normalvektor gegen Aussen hat wie das ursprüngliche Dreieck. Falls ja liegt es
auf der gleichen Ebene, ist also Teil der gleichen Fläche. Diesen Dreieck zeiche
ich. Der vorherige Endpunkt wird jetzt zum mittleren Punkt, und der neue Punkt
zum Endpunkt. Ich widerhole diesen Prozess, bis der Endpunkt und der
Augangspunkt der gleiche Punkt sind. Dann breche ich ab. Jedesmal dass ich ein
Dreieck einzeichne, merke ich mir das es eingezeichnet wurde. Ich speichere auch
jedesmal ab, dass das Dreieck gebildet durch den mittleren Punkt, dem Endpunkt,
und dem richtigen neuen Punkt schon gezeichnet ist. Zwar ist dies nicht direkt
schon gezeichnet, aber dessen Fläche wird nach dem Ende des Algorithmusses schon
eingefüllt sein.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{ma_diagrams/convex_algorithm.png}
	\caption{Der Algorithmus auf einem Sechseck. Merke die zwei wandernde grüne Punkte; das sind immer der mittlere Punkt und der Endpunkt}
	\label{fig:convex}
\end{figure}

Jetzt mache ich die Tiefensuche, die ich Oben beschrieben habe. Ich suche jedes
Dreieck, wo zwei Kanten auch Kanten des Lösungsobjekts sind. Falls dieses
Dreieck noch nicht ausgefüllt ist, lasse ich den Algorithmus laufen.

Warum das immer eine richtige Lösung geben wird: 
\begin{itemize}
  \item Jede Fläche wird Dreiecke enthalten mit so einem Startdreieck, wo zwei
  Kanten Teil des Lösungsobjekts sind.
  \item Es wird von jedem Dreieck, das aufgebaut ist wie ein Startdreieck,
  versucht den Algorithmus zu starten. Nur wenn das Dreieck schon als ausgefüllt
  markiert ist wird der Algorithmus doch nicht laufen gelassen.
  \item Wenn von einem Startdreieck der Algorithmus gestartet wird, wird
  die ganze Fläche ausgefüllt, ohne überlappende Dreiecke.
  \item Es wird nie zweimal die gleiche Fläche ausgefüllt, da alle mögliche
  Startdreiecke während dem Ausfüllen einer Fläche als ausgefüllt markiert werden.
\end{itemize}

% \paragraph{Rotation}

% \begin{itemize}
% 	\item use transformation matrix combinations
% \end{itemize}

\paragraph{Der Kameramanager}
Dieses Modul beinhaltet alles was zur Kamera gehört. Es beinhaltet die Position
und Winkel der Kamera, konstanten die die Dreh- und Bewegungsgschwindigkeit
beeinflussen, sowie die momentane Bewegungsrichtung. Es kann jederzeit eine
Transformationsmatrix vom Kameramanager abgefragt werden, das alle Objekte in der
Welt so bewegt, dass simuliert wird das die Kamera in einer anderen Position
ist. Dies ist nötig, da in OpenGL die Kamera nicht bewegt werden kann.
Stattdessen muss die ganze Welt so gedreht und verschoben werden dass das
Simuliert werden kann. Jeden Tick macht das Kameramanager ausserdem folgende Aktionen:
\begin{itemize}
	\item Es bewegt die Kamera in die Richtung angegeben durch die momentan
	gedrückten Tasten. Falls keine gedrückt sind, bewegt sich die Kamera nicht.
  \item Es berechnet den Transformationsmatrix neu.
\end{itemize}

\paragraph{Das Hyperebenenmanager}
Der Hyperebenenmanager speichert alle nötigen Parameter der Hyperebene. Dies
sind sind ein Vektor, das dessen Position beschreibt, 3 Vektore, die die drei
Einheitsvektore der dreidimensionalen Hyperebene bilden, und ein Normalvektor.
Wie der Kameramanger beinhaltet es auch Konstanten für die Dreh- und
Bewegungsgschwindigkeit. Ausserdem beinhalten es einen Vektor für die momentane
Drehrichtung, und eine Zahl für die momentane Bewegungsrichtung. Die
\code{tick()} Funktion des Hyperebenenmanagers macht folgendes:

\begin{itemize}
  \item Die Hyperebene drehen, jenachdem welche Tasten gedrückt sind.
  \item Die Hyperebene bewegen, falls eine der Bewegungstasten gedrückt ist.
\end{itemize}

\paragraph{Inputmanager}
Der Inputmanager ist nur eine Schnittstelle von GLFW zu meinem Programm. Es
implementiert sogenannte `listener'. Das sind Funktionen, die ich selber nicht
rufen werde, sondern im Fall das eine Taste gedrückt wird, oder die Maus bewegt
wird, von GLFW gerufen werden.

Wenn ein sogenanntes `Mausevent' wahrgenommen wird, ruft es ganz einfach die
richtigen Funktionen vom Kameramanager.

Etwas komplizierter ist was bei einem Tastendruck geschieht. Es hat nämlich zwei
`Keyboardevent's, `Press' und `Release'. `Press' wird genau einmal in dem Moment
gerufen, wenn eine Taste gedrückt wird. Egal wie lange man die Taste gedrückt
hält, es gibt nur einen Event. `Release' wird gerufen, sobald eine Taste
losgelassen wird. 

Für mich ist aber interessant, ob eine Taste momentan gedrückt ist. Ich muss
also selber abspeichern in welchem Zustand welche Tasten sind. Sobald eine Taste
gedrückt wird, merke ich das sie gedrückt ist, und sobald es losgelassen wird
merke ich das es nicht gedrückt ist. Ob eine Taste gedrückt ist oder nicht, kann
dann jedes Modul, wo auf den Inputmanager zugriff hat, abfragen.

\paragraph{Der Renderer}
Der Renderer ist dafür zuständing in jedem Tick mithilfe von OpenGL ein Bild zu
zeichnen. 

Ganz am Anfang beim starten des Programms schickt es die
Schattierungsprogramme durch OpenGL an die Grafikkarte, und reserviert Speicher
auf der Karte für die Daten die es später schicken wird.

Es hat ausserdem eine weitere Funktion, die nicht die \code{render()} Funktion
ist. Mit \code{set\_size()} kann die grösse des Fensters angepasst werden falls
es sich geändert hat. Das wird in der \code{main()} Funktion gerufen, wie schon
beschrieben.

Die \code{render()} Funktion macht folgendes, in dieser Reihenfolge:
\begin{itemize}
  \item Es lässt den Intersektor alle Dreiecke generieren.
  \item Es berechnet die Matrix das die Perspektive der Kamera simuliert.
  \item Es berechnet mithilfe des Kameramanagers den Matrix das die Welt richtig
  dreht und verschiebt.
  \item Es schickt diese Matricen an die Grafikkarte.
  \item Es schickt alle nötigen Daten für die Lichtberechnung wie
  Materialeigenschaften, Lichtintensität und Richtung und die Normalvektore der
  Dreiecke an die Grafikkarte.
  \item Es schickt alle Dreiecke an die Grafikkarte.
  \item Es schickt ein Signal, damit die Grafikkarte ein neues Bild generiert
  und an den Monitor schickt.
\end{itemize}

\paragraph{Shaderprogramme}
Die Shaderprogramme, oder Schattierungsprogramme auf Deutsch sind die Programme
die auf die Grafikkarte geladen werden, und dort mit den von mir angegebenen
Daten die Farbe der einzelnen Pixel berechnen.

Ich habe zwei Shaderprogramme: Einen Vertex- und einen Fragmentshader. Zwischen
diesen beiden Programmen durchlaufen die Daten den Rest des Rendering
Pipeline's, darunter auch die Rasterization. Während der Rasterization werden
alle Daten die spezifisch sind für einzelne Punkte auf das Dreieck interpoliert.

\subparagraph{Lichtberechnung}
Damit man Objekte gut erkennen kann braucht es Lichteffekte. Ohne Lichteffekte
kann man schwer bis garnicht erkennen wo eine Fläche anfängt und wo sie endet,
oder wo die Kanten und Ecken sind. Man sieht nur die Umrisse des Objekts, als
wäre es ein farbiger Schatten. Wenn man sich bewegt kann man die Kanten und
Ecken an den Veränderungen erahnen, aber auch das ist nicht verlässlich.

Also möchten wir Licht simulieren. Das ist aber nicht ganz einfach. In der
echten Welt sehen wir Licht und Schatten, weil Photone von Energiequellen
ausgeschieden werden, die dann an Objekten abspringen, und schliesslich in unser
Auge gehen, das wir dann wahrnehmen. Heutzutage wäre die Simulation von diesem
Verhalten nicht unmöglich; man stösst immer häufiger auf sogenannte Ray-Tracing
Algorithmen. Diese sind aber sehr komplex, und brauchen oft sehr viel
Rechenleistung. Aus diesem Grund wähle ich eine einfachere Methode. Solche
Methoden, welche nicht die echte Physik simulieren, nennen wir oft Modelle.

Eines der weitverbreitetsten Modelle ist das `ADS' Modell. 
\begin{itemize}
  \item \begin{description}
    \item[Ambient reflection] ist überall gleich stark, die Richtung des Lichtes
    und die Position des Punktes auf dem Körper spielt keine Rolle.
  \end{description}
  \item \begin{description}
    \item[Diffuse reflection] ist stärker oder schwächer, jenachdem woher das
    Licht kommt, wo sich der Punkt auf dem Körper im Verhältniss zum Licht
    befindet, und was der Einfallswinkel des Lichtes ist.
  \end{description}
  \item \begin{description}
    \item[Specular reflection] macht einen Körper glänzend. Es rechnet kleine
    Flecken aus, wo das Licht besonders hell erscheint, und bildet glänzende
    Flecken auf dem Körper.
  \end{description}
\end{itemize}

Es existieren viele verschiedene Arten von Belichtungselementen die man
implementieren könnte. Ich werde aber zwei Elemente benutzen: 
\begin{itemize}
  \item \begin{description}
    \item[Ambiente Belichtung], also Licht wo nur eine ambiente Komponente
    enthält. Dies dient als Minimum, nichts kann stockdunkel sein, da alles von
    diesem Licht etwas erhellt wird.
  \end{description}
  \item \begin{description}
    \item[Richtungslicht], Licht das nur eine Richtung hat, nicht aber einen
    Ursprungspunkt. Das Simuliert sehr weit entfernte Lichtquellen, wie zum
    Beispiel die Sonne.
  \end{description}
\end{itemize}

Wie fest ein Objekt auf ambiente, diffuse und spiegelnde Reflektion reagiert,
kommt auf die Materialeigenschaften an. Lichter und Materialien haben beide ADS
Werte. Diese geben wir mit RGBA (Red Green Blue Alpha) an. Materialien haben
ausserdem einen sogenannten Glanzwert $n$; wie Glänzend das Material ist.
\newline
\newline
Für jeden Pixel müssen wir nun die Intensität $I$ der Lichtreflektion bestimmen,
den wir wahrnehmen. Das ist gleich der Summe von der ambienten, diffusen und
spiegelnden Reflektion den wir in diesem Pixel wahrehmen.
\begin{align*}
  I_{beobachtet} &= I_{ambient} + I_{diffus} + I_{spiegelnd}
\end{align*}
Die ambiente Reflexion $I_{ambient}$ setzt sich folgendermassen zusammen:
\begin{align*}
  I_{ambient} &= Licht_{ambient} \cdot Material_{ambient}
\end{align*}
Die diffuse Reflexion $I_{diffus}$ ist schon etwas komplizierter, da es auch vom
Einfallswinkel des Lichtes $\theta$ abhängt. Genauer, die Menge des Lichtes das
vom Punkt reflektiert, ist proportional zu $\cos{\theta}$.
\begin{align*}
  I_{diffus} &= Licht_{diffus} \cdot Material_{diffus} \cdot \cos{\theta}
\end{align*}
Um dies zu berechnen benutzen wir den Normalvektor der Fläche $\hat{N}$, und den
Richtungsvektor des Lichtes $\hat{L}$. Das Skalarprodukt der beiden Vektoren
gibt uns den Cosinus ihres Winkels; genau das brauchen wir. Ausserdem wollen
brauchen wir diffuses Licht nur, wenn $ -90 \leq \theta \leq 90$, da das Licht
sonst gar nicht auf die Oberfläche scheint. Cosinus ist genau in diesem Bereich
positiv. Also benutzen wir folgende Gleichung:
\begin{align*}
  I_{diffus} &= Licht_{diffus} \cdot Material_{diffus} \cdot \max (\hat{N} \cdot \hat{L}, 0)
\end{align*}
Die spiegelnde Reflexion ist etwas spannender. Dies simuliert die überbelichtete
Flecken, wo das Licht durch den Objekt genau in das Auge des Betrachters
reflektiert wird. Wie viel spiegelnde Reflektion in einem Punkt ist, kommt
darauf an, wie klein der Winkel vom austretenden Lichtvektor $\hat{R}$, und dem
Vektor vom Punkt zum Auge $\hat{V}$ ist. Wir können die Cosinusfunktion als
`falloff' Funktion verwenden. Der Glanzwert des Materials ist der Exponent das
die Cosinusfunktion bekommmt. So können wir die Falloff-Funktion stärker oder
schwächer machen. So kommen wir zu der Gleichung:
\begin{align*}
  I_{spiegelnd} &= Licht_{spiegelnd} \cdot Material_{spiegelnd} \cdot \max ({(\hat{R} \cdot \hat{V})}^{n}, 0)
\end{align*}
Wieder nehmen wir nur die positiven Werte. Sonst können spezielle Artifakte
entstehen mit inverser Glanzflecken, flecken wo dünkler sind.
\newline
\newline
Das ist das Phong-Beleuchtungsmodell. Ich habe es aus dem OpenGL Buch, und
Wikipedia gelernt. Es ist ein empirisches Modell; es achtet nicht darauf, das
nicht mehr Licht entsteht durch die Reflexion wie es vor der Reflektion gegeben
hat. Es ist aber ein einfaches Modell, und die Unterschiede zu anderen Modellen
ist nicht gross.

\subparagraph{Der Vertexshader}
Im Vertexshader bearbeitet man einen einzelnen Punkt. Man kann alles daran
verändern. Das machen ich auch. Wie im Renderer beschrieben werden zwei Matricen
an die Grafikkarte geschickt, die die Welt so drehen und wenden, dass die
Kameraposition und die Perspektive stimmen. Diese wenden wir auf den Punkt an.

Anfangs habe ich ausserdem die Position des Punktes genommen, und da die Farbe
des Punktes auch als Vektor repräsentiert wird, es einfach auch als Farbe
angegeben. Das resultierte in einem Objekt, das einen Farbverlauf hatte, da die
Interpolation auch die Farben interpolierte.

Für die Lichteffekte brauche ich aber komplizierterere Shader. Hier für rechne
ich drei Vektore aus der position des Punktes, der Matrixtransform der Kamera,
und dem angegebenem Normalvektor der Fläche. Den Betrachtungsvektor
$\overrightarrow{V}$, den Lichteinfallsvektor $\overrightarrow{L}$ und den
Normalvektor $\overrightarrow{N}$. Ich schike die durch den Rasterizer, und
werde sie erst im Fragmentshader wieder brauchen.

\subparagraph{Der Fragmentshader}
Im Fragmentshader wird ein einzelner Pixel bearbeitet. Hier geben wir an welche
Farbe der Pixel annehmen soll. Wir können Parameter verwenden wie die
Koordinaten des Pixels, oder die Identifikationszahl des Dreiecks zu dem der
Pixel gehört. Ausserdem können wir Daten verwenden die wir weitergeschickt
haben, oder die als konstanten in der Grafikkarte geladen sind von uns.

Vom Vertexshader erhalte ich $\overrightarrow{V}$, $\overrightarrow{L}$ und
$\overrightarrow{N}$. Durch die Interpolation sind sie sogar genau dem Pixel
entsprechend den ich jetzt bearbeite, und nicht ungenau, da der Pixel sich in
der mitte des Dreiecks befinden könnte, und wir diese Vektore nur in den Ecken
des Dreiecks ausrechnen.

Hier rechne ich jetzt $\overrightarrow{R}$ aus. Das geht ganz einfach, ich
spiegle $\overrightarrow{L}$ and $\overrightarrow{N}$.

Jetzt kann ich einfach die Formeln für ambiente, diffuse, und spiegelnde
Reflektion verwenden, und dessen Summe als Farbe ausgeben.

% \section{Literaturverzeichnis}

% Die in der Arbeit erwähnten Quellen (Texte und Abbildungen) werden alphabetisch
% nach Autoren aufgelistet. Für Internetquellen wird eine gesonderte Liste
% erstellt.

% \section{Anhang}

% Hier erscheinen --- wenn sinnvoll --- Rohdaten und Beilagen.

\end{document}